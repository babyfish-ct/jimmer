---
sidebar_position: 7 
title: Trigger
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Jimmer supports triggers that allow users to listen for database changes.

:::tip
Triggers can notify changes not only to objects, but also to associations.
:::

## Trigger Types

### Trigger Classification

-   BinLog Trigger

    This is the default trigger type. It does not affect the SQL generated by Jimmer itself, has higher performance, is triggered after transaction commit, can listen to database changes caused by any reason, including data and changes not caused by Jimmer API; but it requires the underlying database to support binlog.

-   Transaction Trigger

    This trigger does not require the underlying database. It is triggered before transaction commit; its working mechanism is similar to [Alibaba Seata's AT mode](https://seata.io/en-us/docs/dev/mode/at-mode.html). It will generate additional query statements during the modification process to simulate the trigger, which has some impact on modification performance, and can only listen to database changes caused by Jimmer API.

The differences between the two triggers are as follows:

||BinLog Trigger|Transaction Trigger|
|-|-|-|  
|Trigger Time|After transaction commit|Before transaction commit|
|Performance|High|Low|
|Database changes listened|Changes caused by any reason|Only changes caused by calling current application's Jimmer API| 
|Database Requirements|Support and enable binlog|No requirements|
|Working Principle|Use third-party technology to push database binlog changes to message queue, Jimmer application listens to message queue|Any Jimmer modification API automatically implants additional SQL queries to find data changes, similar to [Alibaba Seata's AT mode](https://seata.io/en-us/docs/dev/mode/at-mode.html)|

Apart from the differences in this table, the notification data provided by the two triggers to the user is exactly the same.

### Recommended Usage

-   BinLog Trigger

    The BinLog trigger is triggered after transaction commit, facing the immutable facts.

    That is, the BinLog trigger has no impact on the original transaction, and is allowed to perform time-consuming operations. So it is suitable to execute multiple tasks in its handling logic, especially these tasks:
    
    - Cache consistency maintenance
    - Heterogeneous data source synchronization
    - Send messages to other microservices asynchronously
    
-   Transaction Trigger

    The Transaction trigger is triggered before transaction commit, and its handling logic is injected directly into the current transaction.
    
    If an exception occurs in its event handling logic, it will cause the current business modification to fail; if its handling logic cannot complete quickly, it will cause the current transaction to hold resources for a long time.

    Therefore, the Transaction trigger is suitable for appending more modification behaviors in the current transaction without compromising atomicity.
    
    It is especially suitable for use with [save-command](./save-command). The save-command saves arbitrary complex data structures and is a very black-box, advanced API; while the Transaction trigger can attach some detail monitoring and related redundant data linkage behaviors for the save-command.

## Setting Trigger Type  

Before discussing setting the trigger type, let's see how developers use triggers:

-   `sqlClient.getTriggers()` or `sqlClient.getTriggers(false)`:
    Returns BinLog trigger first, if not exists, returns Transaction trigger.

-   `sqlClient.getTriggers(true)`:
    Explicitly returns Transaction trigger, throws exception if not exists.

To affect the trigger type that can be obtained by `sqlClient.getTriggers()` afterwards, you need to specify TriggerType when building SqlClient.

TriggerType has three possible values:

- BINLOG_ONLY:

    Only supports BinLog trigger, this is the default configuration.
    -   `sqlClient.getTriggers()` and `sqlClient.getTriggers(false)` return BinLog trigger object
    -   `sqlClient.getTriggers(true)` will throw an exception, cannot return Transaction trigger object

- TRANSACTION_ONLY:

    Only supports Transaction trigger.
    No matter what the parameter of `sqlClient.getTriggers` is, it will return the same Transaction trigger object.
    
- BOTH:

    Supports both BinLog trigger and Transaction trigger.
    -   `sqlClient.getTriggers()` and `sqlClient.getTriggers(false)` return BinLog trigger object
    -   `sqlClient.getTriggers(true)` returns Transaction trigger object

Here is a table to compare the three cases:

<table>
  <thead>
    <tr>
      <th></th>
      <th>getTriggers(false)</th>
      <th>getTriggers(true)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>BINLOG_ONLY</td>
      <td>Dedicated BinLog Triggers object</td> 
      <td><span style={{color:'red'}}>Throw exception</span></td>
    </tr>
    <tr>
      <td>TRANSACTION_ONLY</td>
      <td colspan="2"><center><b>Shared</b> Triggers object</center></td>
    </tr>
    <tr>  
      <td>BOTH</td>
      <td>Dedicated BinLog Triggers object</td>
      <td>Dedicated Transaction Triggers object</td> 
    </tr>
  </tbody>
</table>

-   **Q**: Why is `BINLOG_ONLY` the default mode?

    **A**: Transaction triggers implant additional queries in all save operations to simulate triggers, which impacts performance, so it is disabled by default.
    
-   **Q**: In `TRANSACTION_ONLY` mode, why do the two different trigger APIs share the same object?

    **A**: Jimmer's built-in cache consistency strategy must be driven by `sqlClient.getTriggers(false)`, which developers cannot change.

    The purpose is to allow cache consistency maintenance work to not affect the modification transaction, and only start execution after transaction commit. Thus, the original transaction will not be elongated and can end quickly to release lock resources.

    However, not all database products support binlog. In this case, `getTriggers(false)` returns the Transaction trigger object, masquerading as the BinLog trigger object, taking over cache consistency maintenance work that should have been handled by the BinLog trigger.

    That is to say, `TRANSACTION_ONLY` is designed for databases that do not support binlog, **this is the only reason to use this mode**.
    
-   **Q**: In `BOTH` mode, there are two different trigger API objects, does this mean there are two chances to handle any modification?

    **A**: Yes, and this is an important feature.

    Unlike Jimmer's built-in cache consistency mechanism which must be driven by `sqlClient.getTriggers(false)`, the user's business code does not have this limitation. Developers can freely decide whether a handling logic should be registered to `sqlClient.getTriggers(false)` or `sqlClient.getTriggers(true)`, or registered to both at the same time.

    -   If the developer's handling logic contains some data linkage modifications that must participate in the atomic scope of the current transaction, `sqlClient.getTriggers(true)` should be chosen.
    
    -   If the developer's handling logic does not need to participate in the current transaction, `sqlClient.getTriggers(false)` should be chosen to allow the current transaction to end as soon as possible and release lock resources as soon as possible.
    
    -   If the developer's handling logic contains both of the above cases, it should be split into two and registered to the two triggers respectively.

-   **Q**: For databases that do not support binlog, isn't it impossible to do cache cleanup after transaction commit?

    **A**: Not exactly, it can be achieved if the developer is willing to optimize.

    Admittedly, such databases cannot support BinLog triggers, and using Transaction triggers to get data change notifications within the transaction lifetime is the only feasible method.

    However, it is not necessary to perform cache cleanup immediately after receiving the notification, because the cache cleanup work on remote caches like redis has network communication costs and risks of communication failure. Doing so will elongate or even fail the local transaction.

    Jimmer's cache system supports custom CacheOperator. By customizing CacheOperator, the user can override the cache system's deletion behavior, record the cache deletion tasks in ThreadLocal without executing them immediately, and actually execute them after transaction commit.

    -   Unreliable approach:
        1. Use ThreadLocal in custom CacheOperator to record cache entries to be deleted without executing them immediately.
        2. Clear cache in Spring's `AfterCommit` event.

    -   Reliable approach:  
        1. Use ThreadLocal in custom CacheOperator to record cache entries to be deleted without executing them immediately.
        2. Aggregate scattered records into local event table in one shot in Spring's `BeforeCommit` event.
        3. Take data from local event table, clear cache, delete local event table data if successful in Spring's `AfterCommit` event.
        4. Use a polling service to cover the failures in step 3.
        
### Setting Trigger Type in Spring

If using the Jimmer Spring Boot Starter, setting the trigger type is very simple.

Just add a configuration in `application.properties` or `application.yml`. Its name is `jimmer.trigger-type`, and its value is `BINLOG_ONLY` | `TRANSACTION_ONLY` | `BOTH`.

### Setting Trigger Type with Low Level API  

<Tabs groupId="language">
<TabItem value="java" label="Java">

```java
JSqlClient sqlClient = JSqlClient
    .newBuilder()
    // highlight-next-line 
    .setTriggerType(TriggerType.BOTH)
    ...other config omitted...
    .build();
```

</TabItem>

<TabItem value="kotlin" label="Kotlin">

```kotlin
javax.sql.DataSource dataSource = ...;

val sqlClient = newKSqlClient {
    // highlight-next-line
    setTriggerType(TriggerType.BOTH)
    ...other config omitted...
}
```

</TabItem>
</Tabs>

## BinLog Trigger Development Work  

Unlike Transaction triggers, BinLog triggers require third-party technologies to push database binlog changes to the message queue, and applications need to listen to the message queue.

Therefore, just specifying TriggerType as `BINLOG_ONLY` (also the default behavior) when building the SqlClient object is not enough.

There are many choices for the message queue, such as Kafka and RabbitMQ; there are also many choices for third-party technologies to push database binlog incrementally to the message queue, such as MaxWell, Debezium, Canal and DataBus.

Jimmer does not restrict such choices. But to simplify the discussion, this article assumes Kafka is used as the message queue, and Maxwell and Debezium are used as the push technologies.

:::caution  
Because Debezium itself is a kafka-connector, using Debezium inevitably leads to Kafka being the message queue.
:::

### Build External Environment

Before development, the environment needs to be installed first, including the database, Kafka, and Maxwell or Debezium.

-   Maxwell

    1. Enter the local directory corresponding to [example/env-with-cache/maxwell](https://github.com/babyfish-ct/jimmer/blob/main/example/env-with-cache/maxwell) after `git clone`.
        
    2. Execute
        ```sh
        bash ./install.sh
        ```
        
-   Debezium

    1. Enter the local directory corresponding to [example/env-with-cache/debezium](https://github.com/babyfish-ct/jimmer/blob/main/example/env-with-cache/debezium) after `git clone`.

    2. Execute
        ```sh 
        bash ./install.sh
        ```

### Listen to Message Queue  

Whether choosing different databases *(MySQL or Postgres)*, or choosing different push technologies *(Maxwell or Debezium)*, there will be differences in the listening code.

But in any case, the user code is quite similar, divided into the following 4 steps:

1.  Listen to the message queue and get the message body string.

2.  Use [ObjectMapper.readTree](https://fasterxml.github.io/jackson-databind/javadoc/2.7/com/fasterxml/jackson/databind/ObjectMapper.html#readTree(java.lang.String)) for weakly typed parsing of the message text.

    :::info
    So-called weakly typed parsing means the resulting type is [JsonNode](https://fasterxml.github.io/jackson-databind/javadoc/2.7/com/fasterxml/jackson/databind/JsonNode.html), unrelated to business system types. 
    :::
    
3.  Observe the content of the [JsonNode](https://fasterxml.github.io/jackson-databind/javadoc/2.7/com/fasterxml/jackson/databind/JsonNode.html) and extract:

    -   Table name, referred to as `tableName`
    
    -   The sub-[JsonNode](https://fasterxml.github.io/jackson-databind/javadoc/2.7/com/fasterxml/jackson/databind/JsonNode.html) of the old data before modification, referred to as `oldJsonNode`

        > For insert operations, `oldJsonNode` is null

    -   The sub-[JsonNode](https://fasterxml.github.io/jackson-databind/javadoc/2.7/com/fasterxml/jackson/databind/JsonNode.html) of the new data after modification, referred to as `newJsonNode`
    
        > For delete operations, `newJsonNode` is null

    :::info
    The differences in listening code caused by different choices of database and push technology are reflected in this step. However, it is not difficult after observing the message content for inserts, updates, and deletes.
    :::
    
4. Call `JSqlClient.getBinLog().accept` or `KSqlCient.binLog.accept` with `tableName`, `oldJsonNode` and `newJsonNode`.

The following examples demonstrate `MySQL + Maxwell` and `Postgres + Debezium` respectively.

-   MySQL + Maxwell

    For `MySQL + Maxwell`, the message format is typically like:

    ```json 
    {
        "database":"jimmer_demo",
        "table":"book",
        "type":"update",
        "ts":1688592724, 
        "xid":11790,
        "commit":true,
        "data":{
            "id":1,
            "name":"Learning GraphQL",
            "edition":1,
            "price":50,
            "store_id":1,
            "tenant":"a",
            "created_time":"2023-07-05 20:21:00",
            "modified_time":"2023-07-05 20:21:00"
        },
        "old":{
            "store_id":2
        }
    }
    ```

    After a little observation *(it is recommended to look at the messages for insert, update, and delete)*, it is not difficult to implement the following message listening code:

    <Tabs groupId="language">
    <TabItem value="java" label="Java">

    ```java title="MaxwellListener.java"  
    @Component
    public class MaxwellListener {

        private static final ObjectMapper MAPPER = new ObjectMapper();

        private final Caches caches;

        public MaxwellListener(JSqlClient sqlClient) {
            this.caches = sqlClient.getCaches();
        }

        @KafkaListener(topics = "maxwell")
        public void onMaxwellEvent(
                String json,
                Acknowledgment acknowledgment
        ) throws JsonProcessingException {
            JsonNode node = MAPPER.readTree(json);
            String tableName = node.get("table").asText();
            String type = node.get("type").asText();
            JsonNode data = node.get("data");
            switch (type) {
                case "insert":
                    binLog.accept(tableName, null, data);
                    break;
                case "update":
                    binLog.accept(tableName, node.get("old"), data);
                    break;
                case "delete":
                    binLog.accept(tableName, data, null);
                    break;
            }
            acknowledgment.acknowledge();
        }
    }
    ```

    </TabItem>

    <TabItem value="kotlin" label="Kotlin">

    ```kotlin title="MaxwellListener.kt"
    @Component
    class MaxwellListener(sqlClient: KSqlClient) {

        private val caches: KCaches = sqlClient.caches

        @KafkaListener(topics = ["maxwell"])
        fun onMaxwellEvent(
            json: String,
            acknowledgment: Acknowledgment
        ) {
            val node = MAPPER.readTree(json)
            val tableName = node["table"].asText()
            val type = node["type"].asText()
            val data = node["data"]
            when (type) {
                "insert" ->
                    binLog.accept(tableName, null, data)
                "update" ->
                    binLog.accept(tableName, node["old"], data) 
                "delete" ->
                    binLog.accept(tableName, data, null)
            }
            acknowledgment.acknowledge()
        }

        companion object {
            private val MAPPER = ObjectMapper()
        }
    }
    ```

    </TabItem>
    </Tabs>

-   Postgres + Debezium

    For `Postgres + Debezium`, the message format is typically:

    ```json
    {
        "before": {
            "id": 10,
            "name": "GraphQL in Action",
            "edition": 1,
            "price": "H0A=", 
            "store_id": 1,
            "tenant": "b",
            "created_time": 1688590805971294,
            "modified_time": 1688590805971294
        },
        "after": {
            ...omitted...
        },
        "source": {
            "table": "book",
            ...omitted... 
        },
        ...omitted...
    }
    ```
    
    We find some difficulties here, not all data can be directly recognized and converted by Jimmer's BinLog mapping mechanism:
    
    -   Attributes of `BigDecimal` type *(`NUMERIC(M[, D])` in Postgres)* like `Book.price` are displayed as Base64 encoded *(`H0A=` in this example)*.

        This Base64 string is the info processed by [org.apache.kafka.connect.data.Decimal](https://kafka.apache.org/0100/javadoc/org/apache/kafka/connect/data/Decimal.html)

    -   Attributes of `LocalDateTime` type *(TIMESTAMP in Postgres)* are displayed as numbers

    :::info
    Debezium's documentation will explain in detail how its various connectors process certain special data, such as [how pg-connector handles decimal](https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-decimal-types).

    The various connectors in Debezium also provide rich configurations, some of which can be used to change the default data handling method, such as [changing how decimal data is handled](https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-property-decimal-handling-mode), to avoid similar problems.

    However, Debezium's connectors usually serve all systems, and will not deliberately "pamper" a particular application. We cannot assume its configuration will always ensure output that Jimmer can understand directly.

    The examples that come with Jimmer deliberately do not configure the Debezium connector, letting it output kafka-connector specific data to demonstrate how Jimmer solves this problem, same as this article.
    :::
    
    <Tabs groupId="language">
    <TabItem value="java" label="Java">

    ```java title="DebeziumCustomizer.java"
    package ...omitted...;

    import org.apache.kafka.connect.data.Decimal;
    import org.apache.kafka.connect.data.Schema;
    import org.babyfish.jimmer.sql.runtime.Customizer;
    
    ...other imports omitted...

    @Component
    public class DebeziumCustomizer implements Customizer {

        private static final Schema BOOK_PRICE_SCHEMA =
                // Postgres `BOOK.PRICE` is `NUMERIC(10, 2)`, precision is 2
                Decimal.schema(2);

        @Override
        public void customize(JSqlClient.Builder builder) {
            
            builder.setBinLogPropReader( ❶
                    LocalDateTime.class,
                    (prop, jsonNode) -> {
                        return Instant.ofEpochMilli(
                                jsonNode.asLong() / 1000
                        ).atZone(ZoneId.systemDefault()).toLocalDateTime();
                    }
            );

            builder.setBinLogPropReader(
                    BookProps.PRICE, ❷
                    (prop, jsonNode) -> {
                        byte[] bytes = Base64.getDecoder().decode(jsonNode.asText());
                        return Decimal.toLogical(BOOK_PRICE_SCHEMA, bytes);
                    }
            );
        }
    }
    ```

    </TabItem>

    <TabItem value="kotlin" label="Kotlin">

    ```kotlin title="DebeziumCustomizer.kt" 
    package ...omitted...

    import org.apache.kafka.connect.data.Decimal
    import org.apache.kafka.connect.data.Schema
    import org.babyfish.jimmer.sql.kt.cfg.KCustomizer
    
    ...other imports omitted...

    @Component
    class DebeziumCustomizer : KCustomizer {

        override fun customize(dsl: KSqlClientDsl) {

            dsl.setBinLogPropReader(
                LocalDateTime::class ❶
            ) { _, jsonNode ->
                Instant.ofEpochMilli(
                    jsonNode.asLong() / 1000
                ).atZone(ZoneId.systemDefault()).toLocalDateTime()
            }

            dsl.setBinLogPropReader(
                Book::price ❷
            ) { _, jsonNode ->
                Decimal.toLogical(
                    BOOK_PRICE_SCHEMA,
                    Base64.getDecoder().decode(jsonNode.asText())
                )
            }
        }

        companion object {
            private val BOOK_PRICE_SCHEMA =
                // Postgres `BOOK.PRICE` is `NUMERIC(10, 2)`, precision is 2
                Decimal.schema(2)
        }
    }
    ```

    </TabItem>
    </Tabs>

    `setBinLogPropReader` allows developers to customize how to parse attributes in the message that cannot be directly recognized, with two usages:

    -   ❶ Given the return type, specify how a type of attributes should be parsed

    -   ❷ Precisely define how a certain attribute should be parsed

    After solving these problems, the message listening code is easy to implement:

    <Tabs groupId="language">
    <TabItem value="java" label="Java">

    ```java title="DebeziumListener.java"
    @Component
    public class DebeziumListener {

        private static final ObjectMapper MAPPER = new ObjectMapper();

        private final BinLog binLog;

        public DebeziumListener(JSqlClient sqlClient) {
            this.binLog = sqlClient.getBinLog();
        }

        @KafkaListener(topicPattern = "debezium\\..*") 
        public void onDebeziumEvent(
                @Payload(required = false) String json,
                Acknowledgment acknowledgment
        ) throws JsonProcessingException {
            if (json != null) { // Debezium sends empty msg after delete msg
                JsonNode node = MAPPER.readTree(json);
                String tableName = node.get("source").get("table").asText();
                binLog.accept(
                        tableName,
                        node.get("before"),
                        node.get("after")
                );
            }
            acknowledgment.acknowledge();
        }
    }
    ```

    </TabItem>

    <TabItem value="kotlin" label="Kotlin">

    ```kotlin title="DebeziumListener.kt"
    @Component
    class DebeziumListener(sqlClient: KSqlClient) {

        private val binLog: BinLog = sqlClient.binLog

        @KafkaListener(topicPattern = """debezium\..*""")
        fun onDebeziumEvent(
            @Payload(required = false) json: String?,
            acknowledgment: Acknowledgment
        ) {
            if (json !== null) { 
                val node: JsonNode = MAPPER.readTree(json)
                val tableName: String = node["source"]["table"].asText()
                binLog.accept(
                    tableName,
                    node["before"],
                    node["after"]
                )
            }
            acknowledgment.acknowledge()
        }

        companion object {
            private val MAPPER = ObjectMapper()
        }
    }
    ```

    </TabItem>
    </Tabs>

## Usage Examples  

If using BinLog trigger, please enable it first as described above.

### Register Handler Logic

-   Using Jimmer Spring Boot Starter

    If using the Jimmer Spring Boot Starter, trigger events will be sent as Spring events.
    
    So use `@org.springframework.context.event.EventListener` to handle Spring events:

    <Tabs groupId="language">
    <TabItem value="java" label="Java">

    ```java title="DatabaseListener.java"
    @Component
    public class DatabaseListener {

        // highlight-next-line
        @EventListener
        public void onEntityChanged(EntityEvent<?> e) {
            if (e.getImmutableType().getJavaClass() == Book.class) {
                System.out.println("The object `Book` is changed");
                System.out.println("\told: " + e.getOldEntity());
                System.out.println("\tnew: " + e.getNewEntity());
            }
        }

        // highlight-next-line
        @EventListener
        public void onAssociationChanged(AssociationEvent e) {
            if (e.isChanged(BookProps.STORE)) {
                System.out.println("The many-to-one association `Book.store` is changed");
                System.out.println("\tbook id: " + e.getSourceId());
                System.out.println("\tdetached book store id: " + e.getDetachedTargetId());
                System.out.println("\tattached book store id: " + e.getAttachedTargetId());
            } else if (e.isChanged(BookStoreProps.BOOKS)) {
                System.out.println("The one-to-many association `BookStore.books` is changed");
                System.out.println("\tbook store id: " + e.getSourceId());
                System.out.println("\tdetached book id: " + e.getDetachedTargetId());
                System.out.println("\tattached book id: " + e.getAttachedTargetId());
            }
        }
    }
    ```

    </TabItem>

    <TabItem value="kotlin" label="Kotlin">

    ```kotlin title="DatabaseListener.kt"
    @Component
    class DatabaseListener {

        // highlight-next-line
        @EventListener
        fun onEntityChanged(e: EntityEvent<*>) {
            if (e.ImmutableType.javaClass == Book::class.java) {
                println("The object `Book` is changed")
                println("\told: ${e.oldEntity}")
                println("\tnew: ${e.newEntity}")
            }
        }

        // highlight-next-line
        @EventListener
        fun onAssociationChanged(e: AssociationEvent) {
            if (e.isChanged(Book::store)) {
                println("The many-to-one association `Book.store` is changed")
                println("\tbook id: ${e.sourceId}")
                println("\tdetached book store id: ${e.detachedTargetId}")
                println("\tattached book store id: ${e.attachedTargetId}")
            } else if (e.isChanged(BookStore::books)) {
                println("The one-to-many association `BookStore.books` is changed")
                println("\tbook store id: ${e.sourceId}")
                println("\tdetached book id: ${e.detachedTargetId}")
                println("\tattached book id: ${e.attachedTargetId}")
            }
        }
    }
    ```

    </TabItem>
    </Tabs>

-   Using Low Level API

    If not using the Jimmer Spring Boot starter, need to manually register event handler code:

    <Tabs groupId="language">
    <TabItem value="java" label="Java">

    ```java
    // highlight-next-line
    sqlClient.getTriggers().addEntityListener(Book.class, e -> {
        System.out.println("The object `Book` is changed");
        System.out.println("\told: " + e.getOldEntity());
        System.out.println("\tnew: " + e.getNewEntity());
    });
    // highlight-next-line
    sqlClient.getTriggers().addAssociationListener(BookProps.STORE, e -> {
        System.out.println("The many-to-one association `Book.store` is changed");
        System.out.println("\tbook id: " + e.getSourceId());
        System.out.println("\tdetached book store id: " + e.getDetachedTargetId());
        System.out.println("\tattached book store id: " + e.getAttachedTargetId());
    });
    // highlight-next-line
    sqlClient.getTriggers().addAssociationListener(BookStoreProps.BOOKS, e -> {
        System.out.println("The one-to-many association `BookStore.books` is changed");
        System.out.println("\tbook store id: " + e.getSourceId());
        System.out.println("\tdetached book id: " + e.getDetachedTargetId());
        System.out.println("\tattached book id: " + e.getAttachedTargetId());
    });
    ```

    </TabItem>

    <TabItem value="kotlin" label="Kotlin">

    ```kotlin
    // highlight-next-line
    sqlClient.triggers.addEntityListener(Book::class) {
        println("The object `Book` is changed")
        println("\told: ${e.oldEntity}")
        println("\tnew: ${e.newEntity}")
    }
    // highlight-next-line
    sqlClient.triggers.addAssociationListener(Book::store) {
        println("The many-to-one association `Book.store` is changed")
        println("\tbook id: ${e.sourceId}")
        println("\tdetached book store id: ${e.detachedTargetId}")
        println("\tattached book store id: ${e.attachedTargetId}")
    }
    // highlight-next-line
    sqlClient.triggers.addAssociationListener(BookStore::books) {
        println("The one-to-many association `BookStore.books` is changed")
        println("\tbook store id: ${e.sourceId}")
        println("\tdetached book id: ${e.detachedTargetId}")
        println("\tattached book id: ${e.attachedTargetId}") 
    }
    ```

    </TabItem>
    </Tabs>
    
    Where `sqlClient.getTriggers()` or `sqlClient.triggers` is used to register handler logic to the default trigger.

    Can also replace `sqlClient.getTriggers()` or `sqlClient.triggers` with **`sqlClient.getTriggers(true)`** to register handler logic to the Transaction trigger.
    
### Experience Triggers

Now we trigger events to experience triggers.

The BinLog trigger can listen to database changes caused by any reason, even if the database is modified by bypassing the application using any other means. 

For example, you can directly execute:

```sql
update BOOK set STORE_ID = 2 where ID = 7;
```

However, to send events to the Transaction trigger, the database must be modified through Jimmer's API, for example:

<Tabs groupId="language"> 
<TabItem value="java" label="Java">

```java  
BookTable book = BookTable.$;
sqlClient
    .createUpdate(book)
    .set(book.store().id(), 2L)
    .where(book.id().eq(7L))
    .execute();
```

</TabItem>

<TabItem value="kotlin" label="Kotlin">

```kotlin
sqlClient
    .createUpdate(Book::class) {
        set(table.store.id, 2L)
        where(table.id eq 7L)
    }
    .execute()
```

</TabItem>
</Tabs>

The output is:

```
The object `Book` is changed ❶
	old: {"id":7,"name":"Programming TypeScript","edition":1,"price":47.50,"store":{"id":1}}
	new: {"id":7,"name":"Programming TypeScript","edition":1,"price":47.50,"store":{"id":2}}
The many-to-one association `Book.store` is changed ❷  
	book id: 7
	detached book store id: 1
	attached book store id: 2
The one-to-many association `BookStore.books` is changed ❸
	book store id: 1
	detached book id: 7
	attached book id: null
The one-to-many association `BookStore.books` is changed ❹
	book store id: 2
	detached book id: null
	attached book id: 7
```

Where: 

-   ❶ Represents object change event

-   ❷, ❸ and ❹ Represent association change events

:::tip
Jimmer triggers can not only simply convert table changes into object change events, but also convert foreign key changes and middle table changes into association change events.  
:::
